# Report and Instructions

This repository contains functions to construct orthogonal polynomials to a set of data of the form:


$$ data(x) = \lambda_0 + \lambda_1 f_1^{orth} + \lambda_2 f_2^{orth} + \lambda_3 f_3^{orth} + ... $$

and

  $$    f_N^{orth} = \prod_{j=1}^{N} x - \alpha_j  $$

where $\alpha_j$ are chosen such that the inner product of $f_k^{orth}$ and $f_p^{orth}$ is 0 if $k \neq p$ for the given data. 
$\lambda$s are chosen to minimise $X^2$ for a given set of data.

For rare earth element patterns, which are parameterised in terms of their ionic radii, the $\lambda_i$ coefficients describe the contributions of order i polynomials. 
These are useful for geochemical inferences, however it is often difficult to determine how many $\lambda$s are appropriate to describe a pattern, 
given the error in the data.

To decide on how many polynomials probably describe a set of data, this repository also contains functions to determine the most likely amount of $\lambda$ 
coefficicients to describe a data set. It uses the relative probability of the data given the model: 

$$ p(d|m)  \propto  {{1} \over {[(2\pi)^N*|C_{\lambda s}|]^{1/2}}  } exp(-{1\over2} * \phi(m))$$ 

where $d$ is the data, $m$ is the model, $N$ is the number of $\lambda$ fitted to data, $C_{\lambda s}$ is the covariance matrix of the lambdas, and $\phi(m)$ is the error in the data ($X^2$ statistic).
Here, the relative probability calculated is proportional to the true probability, so can be used to find the most likely model, or N.

**Instructions**

The file Code/Code demo.ipynb provides a demonstration on the use of the function in Make_lambdas.py. It runs through how the functions work, 
and demonstrates their use for a data compilation of porphyry-forming intrusives, compiled by Robert Loucks. 
Each line in the Code demo has a markdown line describing what the code is doing. 

For use of the functions provided here, one can download the Make_lambdas.py file from Code/src/python and import them into another program.
The doc-strings in the functions provide information on how each function should be used.

**Dependancies**

This code requires the following packages to be installed:
-numpy
-math
-scipy
-pandas
-sympy
-matplotlib

**Testing**

The code here calculates $\lambda$ coefficients for data in a generalised way for N $\lambda s$, where a user can choose N. This method for constructing $\lambda$ coefficients has,
to the best of my knowledge, not been done before. Therefore, the results must be cross-checked with other methods for constructing $\lambda$ coefficients. 
The programs AlambdaR and BlambdaR (https://earthsciences.anu.edu.au/research/software) do just this, so I cross check my results with those from these programs.

Additionally, the $\lambda$ coefficients should be orthogonal, meaning they are independant of each other. If I have constructed them correctly, then they lower degree $\lambda$s 
should not change when higher degree ones are calculated. This is tested for.

It is difficult to test the probability, as there is nothing to cross check to. I decided to just use it to make sure that generated REE patterns clearly show that
they most likely are described by the number of lambdas they were generated from. 

The test functions can be found in code/src/test_functions.py

**Limitations**

Unfortunately, as is apparent in the Code demo, this sort of analysis suffers from poor data. Where the fit to the model is poor, this analyses decides less $\lambda$
coefficients are most likely to describe the data than is indicated by geological evidence. Additionally, especially in old datasets, instrumental error is occasionally
not reported, and must be estimated. As shown in the Code demo, this can change the most likely number of $\lambda$ coefficients to fit the data. With very good data,
such as those generated by AlambdaR, this probability of fit analysis seems very good and accurate. As such, with high quality datasets, this could be a useful tool
to decide the number of $\lambda$ coefficients to fit to data.
